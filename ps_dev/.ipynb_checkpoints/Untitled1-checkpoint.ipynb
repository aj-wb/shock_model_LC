{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-305347a7be5f>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-305347a7be5f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    mr = merge_rank('./temp/lfs_a09_pqkb_ranked_V2_entrpreneurial_20200423.csv')\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    #### TESTING AS SCRIPT\n",
    "    #---------------------------------- Added: 20200422: <PS>\n",
    "def entre_shock():\n",
    "    mr = merge_rank('./temp/lfs_a09_pqkb_ranked_V2_entrpreneurial_20200423.csv')\n",
    "    if not 'LFS_sector' in mr.columns:\n",
    "        mr = mr.rename(columns={'LFS_sector_x': 'LFS_sector'})\n",
    "        # get subset: a09_pqkb\n",
    "    mr_subset = mr[['hhid_lfs','cc101_lno','LFS_sector','a09_pqkb','c19_pclass','demand_scale', 'w_home','E_sector']]\n",
    "    mr_subset\n",
    "    indexNames = mr_subset[mr_subset['a09_pqkb'] == 'nan' ].index\n",
    "    # Delete these row indexes from dataFrame\n",
    "    mr_subset.drop(indexNames , inplace=True)\n",
    "    mr_subset = mr_subset.reset_index(drop=True)\n",
    " # get subset: c19_pclass\n",
    "\n",
    "    indexNames2 = mr_subset[mr_subset['c19_pclass'] == 'nan' ].index\n",
    "\n",
    "        # Delete these row indexes from dataFrame\n",
    "    mr_subset.drop(indexNames2 , inplace=True)\n",
    "    mr_subset = mr_subset.reset_index(drop=True)\n",
    "    mr_subset\n",
    "\n",
    "    # make new column of combined string a09 && c19:\n",
    "    mr_subset['a09c19'] = mr_subset['a09_pqkb'] +'-'+mr_subset['c19_pclass']\n",
    "\n",
    "        # enforce string:\n",
    "    mr_subset['a09_pqkb'] = [str(q).strip() for q in mr_subset['a09_pqkb']] # enforce type = string\n",
    "    mr_subset['LFS_sector'] = [str(q).strip() for q in mr_subset['LFS_sector']] # enforce type = string\n",
    "    mr_subset['c19_pclass'] = [str(q).strip() for q in mr_subset['c19_pclass']] # enforce type = string\n",
    "    mr_subset['a09c19'] = [str(q).strip() for q in mr_subset['a09c19']] # enforce type = string\n",
    "    if 'E_sector' in mr_subset.columns:\n",
    "        mr_subset['E_sector'] = [str(q).strip() for q in mr_subset['E_sector']] # enforce type = string\n",
    "\n",
    "    mr_subset\n",
    "\n",
    "\n",
    "    x = np.unique(mr_subset.c19_pclass)\n",
    "    x\n",
    "\n",
    "    ### create entrepreneurial table:\n",
    "    #rslt_df = dataframe[dataframe['Percentage'] > 80] \n",
    "    #subsetDataFrame = dfObj[dfObj['Product'].isin(['Mangos', 'Grapes']) ]\n",
    "\n",
    "\n",
    "    # or nonag_wage : private household, private establishment, govt corporation, with pay (family owned business)\n",
    "    df_nonag = mr_subset[~mr_subset['c19_pclass'].isin(['Self Employed', 'Employer','Without Pay (Family owned Business)'])]\n",
    "    df_nonag\n",
    "\n",
    "\n",
    "    # generate fraction by  ENTREPRENEURIAL sector\n",
    "    df_nonag['desc_count'] = df_nonag.groupby('a09_pqkb')['a09_pqkb'].transform('count')# count unique jobs and append to mr_subset\n",
    "    df_nonag['sector_count'] = df_nonag.groupby('E_sector')['E_sector'].transform('count') #count total unique sectors and append to mr_subset\n",
    "    df_nonag['sector_frac'] = df_nonag['desc_count'] / df_nonag['sector_count'] # get fraction of sector as weightin\n",
    "\n",
    "    #### for now we will leave non-ag here\n",
    "\n",
    "    # for entrepreneurial income: self employed, employer, withOUT pay (family owned business)\n",
    "    df_ent = mr_subset[mr_subset['c19_pclass'].isin(['Self Employed', 'Employer','Without Pay (Family owned Business)'])]\n",
    "    df_ent\n",
    "\n",
    "    # generate fraction by  ENTREPRENEURIAL sector\n",
    "    df_ent['desc_count'] = df_ent.groupby('a09_pqkb')['a09_pqkb'].transform('count')# count unique jobs and append to mr_subset\n",
    "    df_ent['sector_count'] = df_ent.groupby('E_sector')['E_sector'].transform('count') #count total unique sectors and append to mr_subset\n",
    "    df_ent['sector_frac'] = df_ent['desc_count'] / df_ent['sector_count'] # get fraction of sector as weightin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     # generate fraction by sector\n",
    "    # mr_subset['desc_count'] = mr_subset.groupby('a09_pqkb')['a09_pqkb'].transform('count')# count unique jobs and append to mr_subset\n",
    "    # mr_subset['sector_count'] = mr_subset.groupby('LFS_sector')['LFS_sector'].transform('count') #count total unique sectors and append to mr_subset\n",
    "    # mr_subset['sector_frac'] = mr_subset['desc_count'] / mr_subset['sector_count'] # get fraction of sector as weighting\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # here, need to insert a new column that merges a09 and c19 -- done\n",
    "    # then, drop duplicates off of this column, so that we can minimize computation\n",
    "\n",
    "    # still need logic to build the logic for each job sector\n",
    "    ## may need to restructure this whole section of code\n",
    "\n",
    "    #####\n",
    "        # drop duplicates (now that overall weighting established)\n",
    "    df_ent = df_ent.drop_duplicates(subset='a09_pqkb')\n",
    "    df_ent = df_ent.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        # generate probability and combine with relative weighting\n",
    "    df_ent['partial_prob'] = np.nan\n",
    "    df_ent['third_col'] = np.nan\n",
    "    df_ent['dummy'] = np.nan\n",
    "\n",
    "        # incorporate Kayenat tables into 'di' &&\n",
    "        # nested logic to incorporate 0-4 scale for social distancing measures\n",
    "        ## where scores of 0 & 1 result in complete job lost, due to unable to distance\n",
    "    i=0\n",
    "    while i < len(df_ent):\n",
    "\n",
    "        if df_ent.demand_scale[i] == 0:\n",
    "\n",
    "            # incorporate 0-4 scale logic:\n",
    "\n",
    "            if df_ent.w_home[i] == 0:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            elif df_ent.w_home[i] == 1:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            else:\n",
    "                df_ent.partial_prob[i] = df_ent.sector_frac[i] * (random.randint(0,50)/100)\n",
    "\n",
    "\n",
    "        elif df_ent.demand_scale[i] == 0.5: \n",
    "\n",
    "            # incorporate 0-4 scale logic:\n",
    "            if df_ent.w_home[i] == 0:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            elif df_ent.w_home[i] == 1:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            else: \n",
    "                df_ent.partial_prob[i] = df_ent.sector_frac[i] * (random.randint(50,100)/100)\n",
    "\n",
    "        elif df_ent.demand_scale[i] == 1.0:\n",
    "            df_ent.partial_prob[i] = df_ent.sector_frac[i]\n",
    "        else:\n",
    "            df_ent.dummy[i] = -99\n",
    "        i = i + 1\n",
    "\n",
    "    # incorporate 3rd column modifiers here:\n",
    "    # if (df_ent['c19_pclass'][i] == \"Gov't/Gov't Corporation\"):\n",
    "    #     df_ent.partial_prob[i] = 0  # essentially reverts the random uniform logic implemented above\n",
    "\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "        # remove nans in summing fields, and dummy storage\n",
    "    del df_ent['dummy']\n",
    "\n",
    "    df_ent['c19_pclass'] == \"Gov't/Gov't Corporation\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # get mean probability by sector:\n",
    "\n",
    "\n",
    "    #storage['fa'] = np.nan\n",
    "    storage = pd.DataFrame(columns=['fa', 'di'], index=[np.unique(df_ent.E_sector)])\n",
    "\n",
    "\n",
    "\n",
    "    for seclist in np.unique(df_ent.E_sector): # hard-coded to existing shock table\n",
    "\n",
    "        pp = df_ent[df_ent.E_sector == seclist]\n",
    "        p4 = 1 - sum(pp.partial_prob)\n",
    "\n",
    "        # build shock table:\n",
    "        storage['fa'][seclist] = storage['fa'][seclist] + p4\n",
    "        print(seclist)\n",
    "\n",
    "\n",
    "\n",
    "    # save to separate var for testing    \n",
    "    rand_weighted_shock = storage\n",
    "\n",
    "    rand_weighted_shock\n",
    "    #return(rand_weighted_shock)\n",
    "\n",
    "\n",
    "\n",
    "    storage = pd.DataFrame(columns = ['sector','fa'])\n",
    "    storage\n",
    "\n",
    "\n",
    "    storage = pd.DataFrame(columns=['fa', 'di'], index=[np.unique(df_ent.E_sector)])\n",
    "    storage\n",
    "\n",
    "    pp = df_ent[df_ent.E_sector == 'Construction']\n",
    "    pp\n",
    "\n",
    "    df_ent[df_ent.E_sector == 'Wholesale and Retail'].partial_prob.sum()\n",
    "\n",
    "    df_ent[df_ent.E_sector == 'Fishing'].partial_prob.sum()\n",
    "\n",
    "    np.unique(df_ent.E_sector) #### the spacing is fucking up the table!\n",
    "\n",
    "    storage = pd.DataFrame(columns=['fa', 'di'], index=[np.unique(df_ent.E_sector)])\n",
    "\n",
    "    for seclist in np.unique(df_ent.E_sector):\n",
    "        pillow = 1 - (df_ent[df_ent.E_sector == seclist].partial_prob.sum())\n",
    "    #     if pillow > 1:\n",
    "    #         pillow = 1\n",
    "        print(pillow)\n",
    "        #storage[seclist]['fa'] = df_ent[df_ent.E_sector == seclist].partial_prob.sum()\n",
    "        #df.loc[0:15,'A'] = 16\n",
    "        storage.loc[seclist,'fa'] = pillow\n",
    "\n",
    "\n",
    "    storage\n",
    "\n",
    "    #     tstamp = (datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "    #     storage.to_csv('./temp/entrep_table_problem_' +tstamp+'.csv')\n",
    "    \n",
    "    return(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
