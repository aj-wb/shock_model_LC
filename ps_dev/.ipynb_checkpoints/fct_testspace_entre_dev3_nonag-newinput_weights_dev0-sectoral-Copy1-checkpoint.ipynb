{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import glob,os\n",
    "import sys\n",
    "import scipy\n",
    "from importlib import  reload\n",
    "from time import process_time \n",
    "#from libraries.lib_gather_data import get_hhid_FIES\n",
    "from datetime import datetime\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from shock_libraries import *\n",
    "from plotting_libraries import *\n",
    "from response_libraries import get_response_sp\n",
    "#\n",
    "from income_shock_libraries_ps import *\n",
    "#\n",
    "from libraries.lib_country_dir import set_directories, load_survey_data, get_places_dict\n",
    "from libraries.lib_get_hh_savings import get_hh_savings\n",
    "from libraries.pandas_helper import broadcast_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting & aesthetics\n",
    "font = {'family':'sans serif', 'size':10}\n",
    "plt.rc('font', **font)\n",
    "mpl.rcParams['xtick.labelsize'] = 10\n",
    "mpl.rcParams['ytick.labelsize'] = 10\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns_pal = sns.color_palette('Set1', n_colors=8, desat=.4)\n",
    "greys_pal = sns.color_palette('Greys', n_colors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = rand_weighted_shock_3dim_v2_edit()\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entre_shock(s_sector='LFS_sector'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    mr = merge_rank('./temp/lfs_a09_pqkb_ranked_V2_entrpreneurial_20200423.csv')\n",
    "    if not 'LFS_sector' in mr.columns:\n",
    "        mr = mr.rename(columns={'LFS_sector_x': 'LFS_sector'})\n",
    "        # get subset: a09_pqkb\n",
    "    mr_subset = mr[['hhid_lfs','cc101_lno','LFS_sector','a09_pqkb','c19_pclass','demand_scale', 'w_home','E_sector','pwgt']]\n",
    "    mr_subset\n",
    "    indexNames = mr_subset[mr_subset['a09_pqkb'] == 'nan' ].index\n",
    "    # Delete these row indexes from dataFrame\n",
    "    mr_subset.drop(indexNames , inplace=True)\n",
    "    mr_subset = mr_subset.reset_index(drop=True)\n",
    "    # get subset: c19_pclass\n",
    "\n",
    "    indexNames2 = mr_subset[mr_subset['c19_pclass'] == 'nan' ].index\n",
    "\n",
    "        # Delete these row indexes from dataFrame\n",
    "    mr_subset.drop(indexNames2 , inplace=True)\n",
    "    mr_subset = mr_subset.reset_index(drop=True)\n",
    "    mr_subset\n",
    "\n",
    "    # make new column of combined string a09 && c19:\n",
    "    mr_subset['a09c19'] = mr_subset['a09_pqkb'] +'-'+mr_subset['c19_pclass']\n",
    "\n",
    "        # enforce string:\n",
    "    mr_subset['a09_pqkb'] = [str(q).strip() for q in mr_subset['a09_pqkb']] # enforce type = string\n",
    "    mr_subset['LFS_sector'] = [str(q).strip() for q in mr_subset['LFS_sector']] # enforce type = string\n",
    "    mr_subset['c19_pclass'] = [str(q).strip() for q in mr_subset['c19_pclass']] # enforce type = string\n",
    "    mr_subset['a09c19'] = [str(q).strip() for q in mr_subset['a09c19']] # enforce type = string\n",
    "    if 'E_sector' in mr_subset.columns:\n",
    "        mr_subset['E_sector'] = [str(q).strip() for q in mr_subset['E_sector']] # enforce type = string\n",
    "\n",
    "    mr_subset\n",
    "\n",
    "\n",
    "    x = np.unique(mr_subset.c19_pclass)\n",
    "    x\n",
    "\n",
    "    ### create entrepreneurial table:\n",
    "    #rslt_df = dataframe[dataframe['Percentage'] > 80] \n",
    "    #subsetDataFrame = dfObj[dfObj['Product'].isin(['Mangos', 'Grapes']) ]\n",
    "\n",
    "\n",
    "    # or nonag_wage : private household, private establishment, govt corporation, with pay (family owned business)\n",
    "    df_nonag = mr_subset #[~mr_subset['c19_pclass'].isin(['Self Employed', 'Employer','Without Pay (Family owned Business)'])]\n",
    "    df_nonag\n",
    "\n",
    "\n",
    "    # generate fraction by  ENTREPRENEURIAL sector\n",
    "    #df_nonag['desc_count'] = df_nonag.groupby('a09_pqkb')['a09_pqkb'].transform('count')# count unique jobs and append to mr_subset\n",
    "    #df_nonag['sector_count'] = df_nonag.groupby('E_sector')['E_sector'].transform('count') #count total unique sectors and append to mr_subset\n",
    "\n",
    "    df_nonag['sector_count'] = df_nonag.groupby(s_sector)['pwgt'].transform('sum') #count total unique sectors and append to mr_subset\n",
    "    df_nonag['desc_count'] = df_nonag.groupby('a09_pqkb')['pwgt'].transform('sum') #count total unique sectors and append to mr_subset\n",
    "\n",
    "    df_nonag['sector_frac'] = df_nonag['desc_count'] / df_nonag['sector_count'] # get fraction of sector as weightin\n",
    "\n",
    "    #### for now we will leave non-ag here\n",
    "\n",
    "    # for entrepreneurial income: self employed, employer, withOUT pay (family owned business)\n",
    "    df_ent = mr_subset #[~mr_subset['c19_pclass'].isin(['Self Employed', 'Employer','Without Pay (Family owned Business)'])]\n",
    "\n",
    "    #####  ###### #####\n",
    "    #RUNNING AG\n",
    "    df_ent = df_nonag\n",
    "\n",
    "    ##### ###### #####\n",
    "\n",
    "    #####\n",
    "    # here, need to insert a new column that merges a09 and c19 -- done\n",
    "    # then, drop duplicates off of this column, so that we can minimize computation\n",
    "\n",
    "    # still need logic to build the logic for each job sector\n",
    "    ## may need to restructure this whole section of code\n",
    "\n",
    "    #####\n",
    "        # drop duplicates (now that overall weighting established)\n",
    "    df_ent = df_ent.drop_duplicates(subset='a09_pqkb')\n",
    "    df_ent = df_ent.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        # generate probability and combine with relative weighting\n",
    "    df_ent['partial_prob'] = np.nan\n",
    "    df_ent['third_col'] = np.nan\n",
    "    df_ent['dummy'] = np.nan\n",
    "\n",
    "        # incorporate Kayenat tables into 'di' &&\n",
    "        # nested logic to incorporate 0-4 scale for social distancing measures\n",
    "        ## where scores of 0 & 1 result in complete job lost, due to unable to distance\n",
    "    i=0\n",
    "    while i < len(df_ent):\n",
    "\n",
    "        if df_ent.demand_scale[i] == 0:\n",
    "\n",
    "            # incorporate 0-4 scale logic:\n",
    "\n",
    "            if df_ent.w_home[i] == 0:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            elif df_ent.w_home[i] == 1:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            else:\n",
    "                df_ent.partial_prob[i] = df_ent.sector_frac[i] * (random.randint(0,50)/100)\n",
    "\n",
    "\n",
    "        elif df_ent.demand_scale[i] == 0.5: \n",
    "\n",
    "            # incorporate 0-4 scale logic:\n",
    "            if df_ent.w_home[i] == 0:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            elif df_ent.w_home[i] == 1:\n",
    "                df_ent.partial_prob[i] = 0\n",
    "\n",
    "            else: \n",
    "                df_ent.partial_prob[i] = df_ent.sector_frac[i] * (random.randint(50,100)/100)\n",
    "\n",
    "        elif df_ent.demand_scale[i] == 1.0:\n",
    "            df_ent.partial_prob[i] = df_ent.sector_frac[i]\n",
    "        else:\n",
    "            df_ent.dummy[i] = -99\n",
    "        i = i + 1\n",
    "\n",
    "    # incorporate 3rd column modifiers here:\n",
    "    # if (df_ent['c19_pclass'][i] == \"Gov't/Gov't Corporation\"):\n",
    "    #     df_ent.partial_prob[i] = 0  # essentially reverts the random uniform logic implemented above\n",
    "        if (df_ent['c19_pclass'][0] == \"Gov't/Gov't Corporation\"):\n",
    "            df_ent.partial_prob[i] = 1  # essentially reverts the random uniform logic implemented above\n",
    "\n",
    "        # remove nans in summing fields, and dummy storage\n",
    "    del df_ent['dummy']\n",
    "\n",
    "    df_ent['c19_pclass'] == \"Gov't/Gov't Corporation\"\n",
    "\n",
    "\n",
    "    # get mean probability by sector:\n",
    "\n",
    "\n",
    "    #storage['fa'] = np.nan\n",
    "    storage = pd.DataFrame(columns=['fa', 'di'], index=[np.unique(df_ent[s_sector])])\n",
    "    storage.index.names = ['sector']\n",
    "    # # save to separate var for testing    \n",
    "    # rand_weighted_shock = storage\n",
    "\n",
    "    # rand_weighted_shock\n",
    "    # #return(rand_weighted_shock)\n",
    "\n",
    "    # storage = pd.DataFrame(columns=['fa', 'di'], index=[np.unique(df_ent.E_sector)])\n",
    "\n",
    "    # iterate through loop of sector names\n",
    "    for seclist in np.unique(df_ent[s_sector]):\n",
    "        pillow = 1 - (df_ent[df_ent[s_sector] == seclist].partial_prob.sum())\n",
    "\n",
    "        storage.loc[seclist,'fa'] = pillow\n",
    "        storage.loc[seclist,'di'] = 1\n",
    "\n",
    "\n",
    "    \n",
    "    tstamp = (datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "    #storage.to_csv('./temp/table_'+s_sector+'_' +tstamp+'.csv')\n",
    "    #storage\n",
    "    return(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa</th>\n",
       "      <th>di</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ag</th>\n",
       "      <td>0.0198345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction</th>\n",
       "      <td>0.749147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eduhealth</th>\n",
       "      <td>0.473848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>0.103174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_entertainment</th>\n",
       "      <td>0.979552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>0.00416928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>-1.11022e-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturing</th>\n",
       "      <td>0.78067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mining</th>\n",
       "      <td>0.797618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.983124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_services</th>\n",
       "      <td>0.398077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>0.353294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transportation</th>\n",
       "      <td>0.92604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utilities</th>\n",
       "      <td>0.205196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholesale</th>\n",
       "      <td>0.713962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fa di\n",
       "sector                               \n",
       "ag                       0.0198345  1\n",
       "construction              0.749147  1\n",
       "eduhealth                 0.473848  1\n",
       "finance                   0.103174  1\n",
       "food_entertainment        0.979552  1\n",
       "government              0.00416928  1\n",
       "information           -1.11022e-15  1\n",
       "manufacturing              0.78067  1\n",
       "mining                    0.797618  1\n",
       "other                     0.983124  1\n",
       "professional_services     0.398077  1\n",
       "retail                    0.353294  1\n",
       "transportation             0.92604  1\n",
       "utilities                 0.205196  1\n",
       "wholesale                 0.713962  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = entre_shock()\n",
    "xx\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shock_100_entre():  # initialize shock sector storage dataframe\n",
    "   \n",
    "    '''\n",
    "   current hard coding for sensitivity analysis, 20200413: requires cleaning for further implementation\n",
    "   - addition of modularity\n",
    "   - \n",
    "   - current functionality:\n",
    "       - outputs csv to location: './temp/sect_iter_100.csv\n",
    "       - containing data frame with 101 simulations of <rand_weighted_shock_distance():\n",
    "    - runtime: ~10minutes\n",
    "   '''\n",
    "\n",
    "    stor = entre_shock()\n",
    "    del stor['di']\n",
    "\n",
    "    # set number of iterations\n",
    "    p = 0\n",
    "    n_iter = 99\n",
    "\n",
    "    # model and store stochastic sector response\n",
    "    while p < n_iter:\n",
    "        \n",
    "        new_val = entre_shock()\n",
    "        del new_val['di']\n",
    "        new_val = new_val.rename(columns={'fa': ('iter'+str(p))})\n",
    "\n",
    "        # pd.merge(labor,rank, on=merge_col, how='left')\n",
    "        stor = pd.merge(stor,new_val,on='sector', how='left')\n",
    "        p = p+ 1\n",
    "        print(p)\n",
    "        \n",
    "    tstamp = (datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "    stor.to_csv('./temp/entre_shock_mc_fullsector_'+tstamp+ '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.6/site-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "generate_shock_100_entre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shock_stats_entre():\n",
    "    # generate shock table statistics\n",
    "    #df['mean'] = df.mean(axis=1)\n",
    "\n",
    "    # load csv to dataframe:\n",
    "    #dfs = pd.read_csv('./temp/sect_iter_100.csv') # original\n",
    "    dfs = pd.read_csv('./temp/entre_shock_mc_fullsector_20200427_1252.csv') # modified 20200420\n",
    "    # set index to LFS_sector\n",
    "    dfs.set_index('sector')\n",
    "\n",
    "    # compute statistics:\n",
    "    dfs['mean'] = dfs.mean(axis=1)\n",
    "    #print(dfs['mean'])\n",
    "    dfs['std_dev'] = dfs.std(axis=1)\n",
    "    #print(dfs['std_dev'])\n",
    "\n",
    "    #round to 3 dec:\n",
    "    dfs['mean'] = [(round(q, 3)) for q in dfs['mean']]\n",
    "    dfs['std_dev'] = [(round(q, 3)) for q in dfs['std_dev']]\n",
    "\n",
    "    # new datafame storing just info:\n",
    "    df_stat = dfs[['sector','mean','std_dev']].set_index('sector')\n",
    "    df_stat\n",
    "    # df_stat.to_csv('./temp/phi_get_shock_input.csv') # original\n",
    "    tstamp = (datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "    df_stat.to_csv('./temp/phi_fullsector_'+tstamp+'.csv') # modified 20200420\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(df_stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ag</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eduhealth</th>\n",
       "      <td>0.443</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_entertainment</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturing</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mining</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_services</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transportation</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utilities</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholesale</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean  std_dev\n",
       "sector                               \n",
       "ag                     0.017    0.002\n",
       "construction           0.761    0.122\n",
       "eduhealth              0.443    0.044\n",
       "finance                0.096    0.028\n",
       "food_entertainment     0.977    0.004\n",
       "government             0.004    0.000\n",
       "information           -0.000    0.000\n",
       "manufacturing          0.768    0.009\n",
       "mining                 0.743    0.090\n",
       "other                  0.983    0.000\n",
       "professional_services  0.400    0.094\n",
       "retail                 0.352    0.001\n",
       "transportation         0.931    0.011\n",
       "utilities              0.205    0.000\n",
       "wholesale              0.714    0.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shock_stats_entre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the shock table\n",
    "def get_phi_shock(flavor=0):\n",
    "    \"\"\"\n",
    "    20200426: loads shock tables\n",
    "    \n",
    "    input: flavor\n",
    "        options:\n",
    "            0 -- default shock table, in original model\n",
    "            1 -- sectoral shock table, based on scoring\n",
    "            2 -- nonag_shock table, sector names v2\n",
    "            3 -- entrepreneurial shock table, sector names v2\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if flavor == 0:\n",
    "        # default shock table:\n",
    "        shock_default = { 'ag':           [  0,  0],\n",
    "                 'mining':        [  0,  0],\n",
    "                 'utilities':     [  0,  0],\n",
    "                 'construction':  [0.5,1.0],\n",
    "                 'manufacturing': [0.1,1.0],\n",
    "                 'wholesale':     [0.1,1.0],\n",
    "                 'retail':        [0.5,1.0],\n",
    "                 'transportation':[0.5,1.0],\n",
    "                 'information':   [0.1,1.0],\n",
    "                 'finance':       [0.1,1.0],\n",
    "                 'professional_services':[0.1,1.0],\n",
    "                 'eduhealth':     [0.1,1.0],\n",
    "                 'food_entertainment':[0.8,1.0],\n",
    "                 'government':    [  0,  0],\n",
    "                 'other':         [0.8,1.0]}\n",
    "        df_shock = pd.DataFrame(data=shock_default).T\n",
    "        df_shock.columns = ['fa','di']\n",
    "        df_shock.index.name = 'sector'\n",
    "        shock_table = df_shock\n",
    "    \n",
    "    if flavor == 1:\n",
    "        # sectoral shock table\n",
    "        df = pd.read_csv('./temp/phi_shocks/phi_shock_3dimv2.csv').set_index('LFS_sector')\n",
    "        df = df.rename(columns={'mean': 'fa', 'std_dev':'di'}) \n",
    "        df['di'] = 1\n",
    "        \n",
    "        #print(flavor)\n",
    "        #print(df)\n",
    "        shock_table = df\n",
    "        \n",
    "    if flavor == 2:\n",
    "        #nonag shock table\n",
    "        df = pd.read_csv('./temp/phi_shocks/phi_nonag.csv').set_index('sector')\n",
    "        df = df.rename(columns={'mean': 'fa', 'std_dev':'di'}) \n",
    "        df['di'] = 1\n",
    "       # print(flavor)\n",
    "        shock_table = df\n",
    "        \n",
    "    if flavor == 3:\n",
    "        #entrepreneurial shock table\n",
    "        df = pd.read_csv('./temp/phi_shocks/phi_entre.csv').set_index('sector')\n",
    "        df = df.rename(columns={'mean': 'fa', 'std_dev':'di'}) \n",
    "        df['di'] = 1\n",
    "        shock_table = df\n",
    "        \n",
    "        \n",
    "        #print(flavor)\n",
    "   \n",
    "    \n",
    "    return(shock_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = get_phi_shock(3)\n",
    "xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
